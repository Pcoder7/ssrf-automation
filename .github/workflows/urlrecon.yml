name: Url Recon with Gf 

on:
  schedule:
    - cron: "0 10 * * *"  # Runs every day at 10:00 AM UTC
  workflow_dispatch:

permissions:
    contents: write

jobs:
  # JOB 1: Prepares the list of domains to create the parallel job matrix.
  setup-matrix:
    runs-on: ubuntu-latest
    outputs:
      domains: ${{ steps.set-matrix.outputs.domains }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Create domain matrix from domains.txt
        id: set-matrix
        run: |
          # Exit gracefully if domains.txt does not exist
          if [ ! -f domains.txt ]; then
            echo "domains.txt file not found! Skipping."
            echo "domains=[]" >> $GITHUB_OUTPUT
            exit 0
          fi
          

          SANITIZED_DOMAINS=$(awk '!/^\s*#/ && !/^\s*$/ { gsub(/^[ \t]+|[ \t]+$/, ""); print }' domains.txt)
          
          JSON_DOMAINS=$(echo "$SANITIZED_DOMAINS" | jq -R . | jq -sc .)
          
          echo "domains=$JSON_DOMAINS" >> $GITHUB_OUTPUT
          echo "Matrix created: $JSON_DOMAINS"

  # JOB 2: Runs recon tools in parallel for each domain from the matrix.
  recon-parallel:
    needs: setup-matrix
    # Only run this job if the setup job actually found domains to process.
    if: needs.setup-matrix.outputs.domains != '[]'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false # IMPORTANT: If one domain scan fails, the others will continue.
      matrix:
        domain: ${{ fromJson(needs.setup-matrix.outputs.domains) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'


      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-
            
      - name: Install Tools (gau, gf, uro)
        run: |
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install -v github.com/tomnomnom/gf@latest
          go install github.com/tomnomnom/waybackurls@latest
          go install -v github.com/tomnomnom/anew@latest
          python3 -m pip install --user pipx
          python3 -m pipx ensurepath
          pipx install uro
          pip install waymore
          pip install urless          
          echo "$HOME/go/bin" >> $GITHUB_PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install uforall
        run: |
           wget https://github.com/rix4uni/uforall/releases/download/v0.0.2/uforall-linux-amd64-0.0.2.tgz
           tar -xvzf uforall-linux-amd64-0.0.2.tgz
           rm -rf uforall-linux-amd64-0.0.2.tgz
           mv uforall ~/go/bin/uforall
           echo $GOPATH
      
      - name: Install uforall
        run: |
           wget https://github.com/rix4uni/timelimitx/releases/download/v0.0.1/timelimitx-linux-amd64-0.0.1.tgz
           tar -xvzf timelimitx-linux-amd64-0.0.1.tgz
           rm -rf timelimitx-linux-amd64-0.0.1.tgz
           mv timelimitx ~/go/bin/timelimitx
           
          
      - name: Setup gf-patterns
        run: |
          git clone https://github.com/1ndianl33t/Gf-Patterns.git
          mkdir -p ~/.gf
          cp Gf-Patterns/*.json ~/.gf
          rm -rf Gf-Patterns

      - name: Process Recon for ${{ matrix.domain }}
        run: |
          domain="${{ matrix.domain }}"
          echo "--- Processing domain: $domain ---"
          mkdir -p "results/$domain"
          OUTDIR="results/$domain"
          Gau_blacklist="png,jpg,gif,css,ico,jpeg,bmp,svg,img,mp4,flv,ogv,webm,webp,mov,mp3,m4a,m4p,scss,tif,tiff,ttf,otf,woff,woff2,eot,htc,rtf,swf,image"

          
          URO_BLACKLIST="css ico jpg jpeg png bmp svg img gif mp4 flv ogv webm webp mov mp3 m4a m4p scss tif tiff ttf otf woff woff2 bmp ico eot htc rtf swf image js"
          
          echo "[*] Fetching and filtering URLs for $domain"


          echo "$domain" | gau --subs --blacklist $Gau_blacklist | sort -u | uro -b "$URO_BLACKLIST" --filters hasparams | anew -q "results/$domain/filtered.txt"
        
          timelimitx -t 10m "waymore -i \"$domain\" -mode U -oU \"$OUTDIR/waymore.txt\""

          cat "$OUTDIR/waymore.txt" | uro -b "$URO_BLACKLIST" --filters hasparams | anew -q "results/$domain/filtered.txt"
          
          echo "[*] Extracting vulnerability candidates with gf"
          cat "results/$domain/filtered.txt" | gf ssrf > "results/$domain/ssrf.txt"
          cat "results/$domain/filtered.txt" | gf lfi > "results/$domain/lfi.txt"
          cat "results/$domain/filtered.txt" | gf sqli > "results/$domain/sqli.txt"

      - name: Upload Domain Results as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: recon-results-${{ matrix.domain }} # Unique artifact for each domain
          path: results/ # Uploads the results specific to this domain job
          retention-days: 1

  # JOB 3: Aggregates all results and commits them sequentially. This is the "loop" you requested.
  aggregate-and-commit:
    needs: recon-parallel
    if: always() # Ensures this job runs even if some parallel recon jobs failed.
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository 
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Install rsync
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y rsync

      - name: Create Directory for New Scan Results
        run: mkdir new-results

      - name: Download Artifacts into New Results Directory
        uses: actions/download-artifact@v4
        with:
          path: new-results
          pattern: recon-results-*
          merge-multiple: true

      - name: Differentiate and Commit Changes
        id: commit
        run: |
          echo "Preparing to differentiate and commit results..."
          
          # Step 1: Check if any results were actually downloaded.
          # We check if the new-results directory is empty. If it is, we stop.
          if [ -z "$(ls -A new-results)" ]; then
            echo "No artifacts were downloaded. Nothing to commit."
            echo "pushed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Step 2: Prepare the new results for comparison.
          echo "Cleaning new results before comparison..."
          find new-results -type f -print0 | while IFS= read -r -d '' file; do
            if [[ $(file --brief --mime-encoding "$file") == "binary" ]]; then
              echo "Removing binary file: $file"
              rm "$file"
            fi
          done
          find new-results -type f -size 0 -delete
          find new-results -type d -empty -delete
          
          # --- THE CRITICAL FIX IS HERE ---
          # Step 3: Synchronize the new results with the repository's working directory.
          # The source is 'new-results/' (the contents of the directory).
          # The destination is 'results/' (the target directory in the repository).
          echo "Synchronizing new results with the repository..."
          rsync -av --delete new-results/ results/
          
          # Step 4: Configure Git user.
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          
          # Step 5: Add all changes and check if a commit is necessary.
          git add results/
          
          if ! git diff --staged --quiet; then
            echo "Changes detected. Committing to the repository."
            git commit -m "recon: Automated scan results"
            echo "pushed=true" >> $GITHUB_OUTPUT
          else
            echo "No new changes to commit."
            echo "pushed=false" >> $GITHUB_OUTPUT
          fi

      - name: Push Changes with Retry Logic
        if: steps.commit.outputs.pushed == 'true'
        run: |
          for i in {1..5}; do
            echo "Attempting to push changes (attempt $i/5)..."
            git push && break || true
            if [ $i -eq 5 ]; then
              echo "All 5 push attempts failed. The job will now fail."
              exit 1
            fi
            echo "Push failed. Retrying in 20 seconds..."
            sleep 20
          done
          echo "Push successful."

