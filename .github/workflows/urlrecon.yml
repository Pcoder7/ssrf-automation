name: Parallel Recon with Sequential Commit

on:
  schedule:
    - cron: "0 10 * * *"  # Runs every day at 10:00 AM UTC
  workflow_dispatch:

permissions:
    contents: write

jobs:
  # JOB 1: Prepares the list of domains to create the parallel job matrix.
  setup-matrix:
    runs-on: ubuntu-latest
    outputs:
      domains: ${{ steps.set-matrix.outputs.domains }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Create domain matrix from domains.txt
        id: set-matrix
        run: |
          # Exit gracefully if domains.txt does not exist
          if [ ! -f domains.txt ]; then
            echo "domains.txt file not found! Skipping."
            echo "domains=[]" >> $GITHUB_OUTPUT
            exit 0
          fi
          

          SANITIZED_DOMAINS=$(awk '!/^\s*#/ && !/^\s*$/ { gsub(/^[ \t]+|[ \t]+$/, ""); print }' domains.txt)
          
          JSON_DOMAINS=$(echo "$SANITIZED_DOMAINS" | jq -R . | jq -sc .)
          
          echo "domains=$JSON_DOMAINS" >> $GITHUB_OUTPUT
          echo "Matrix created: $JSON_DOMAINS"

  # JOB 2: Runs recon tools in parallel for each domain from the matrix.
  recon-parallel:
    needs: setup-matrix
    # Only run this job if the setup job actually found domains to process.
    if: needs.setup-matrix.outputs.domains != '[]'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false # IMPORTANT: If one domain scan fails, the others will continue.
      matrix:
        domain: ${{ fromJson(needs.setup-matrix.outputs.domains) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'


      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-
            
      - name: Install Tools (gau, gf, uro)
        run: |
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install -v github.com/tomnomnom/gf@latest
          python3 -m pip install --user pipx
          python3 -m pipx ensurepath
          pipx install uro
          echo "$HOME/go/bin" >> $GITHUB_PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Setup gf-patterns
        run: |
          git clone https://github.com/1ndianl33t/Gf-Patterns.git
          mkdir -p ~/.gf
          cp Gf-Patterns/*.json ~/.gf
          rm -rf Gf-Patterns

      - name: Process Recon for ${{ matrix.domain }}
        run: |
          domain="${{ matrix.domain }}"
          echo "--- Processing domain: $domain ---"
          mkdir -p "results/$domain"
          Gau_blacklist="png,jpg,gif,css,ico,jpeg,bmp,svg,img,mp4,flv,ogv,webm,webp,mov,mp3,m4a,m4p,scss,tif,tiff,ttf,otf,woff,woff2,eot,htc,rtf,swf,image"
          
          URO_BLACKLIST="css ico jpg jpeg png bmp svg img gif mp4 flv ogv webm webp mov mp3 m4a m4p scss tif tiff ttf otf woff woff2 bmp ico eot htc rtf swf image js"
          echo "[*] Fetching and filtering URLs for $domain"
          echo "$domain" | gau --subs --blacklist $Gau_blacklist | sort -u | uro -b "$URO_BLACKLIST" --filters hasparams -o "results/$domain/filtered.txt"

          echo "[*] Extracting vulnerability candidates with gf"
          cat "results/$domain/filtered.txt" | gf ssrf > "results/$domain/ssrf.txt"
          cat "results/$domain/filtered.txt" | gf lfi > "results/$domain/lfi.txt"
          cat "results/$domain/filtered.txt" | gf sqli > "results/$domain/sqli.txt"

      - name: Upload Domain Results as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: recon-results-${{ matrix.domain }} # Unique artifact for each domain
          path: results/ # Uploads the results specific to this domain job
          retention-days: 1

  # JOB 3: Aggregates all results and commits them sequentially. This is the "loop" you requested.
  aggregate-and-commit:
    needs: recon-parallel
    if: always() # This ensures this job runs even if some parallel recon jobs failed.
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Download all domain results from artifacts
        uses: actions/download-artifact@v4
        with:
          path: . # Download to the workspace root
          pattern: recon-results-* # Match all artifacts from the parallel jobs
          merge-multiple: true # Merges all 'results' directories into one

      - name: Commit Text-Only Results
        run: |
          echo "Preparing to commit results..."
          
          # Step 1: Remove any binary files to ensure only text is committed.
          find results -type f -print0 | while IFS= read -r -d '' file; do
            if [[ $(file --brief --mime-encoding "$file") == "binary" ]];
            then
              echo "Removing binary file: $file"
              rm "$file"
            fi
          done
          
          # Step 2: Find and delete any result directories that are empty.
          # This prevents the 'nothing added to commit' error.
          
          echo "Cleaning up empty result directories..."
          find results/* -type d -empty -delete
          
          # Step 3: Check if there are any *actual* changes left to commit.
          if [[ -z $(git status --porcelain) ]]; then
            echo "No new results or changes to commit."
            exit 0
          fi
          
          # Step 4: Configure Git and commit all results in a single, safe transaction.
          echo "New results found. Committing to the repository."
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          git add results/
          git commit -m "recon: Automated Url Recon Results"
          git push

